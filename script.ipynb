{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #openCV\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose #pose estimation models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens the video feed and close with the press 'q'\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Mediapipe Feed', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens the video feed and close with the press 'q'\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "\n",
    "        results=pose.process(image)\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "    \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Joints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://google.github.io/mediapipe/images/mobile/pose_tracking_full_body_landmarks.png\" alt=\"pose_tracking_full_body_landmarks.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens the video feed and close with the press 'q'\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "\n",
    "        results=pose.process(image)\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # extract the landmarks\n",
    "        try :\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "    \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks)\n",
    "# 33 for 33 joints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[x: 0.2782760262489319\n",
      "y: 0.6696892380714417\n",
      "z: -0.8596245646476746\n",
      "visibility: 0.9995396733283997\n",
      ", x: 0.28461796045303345\n",
      "y: 0.6047347784042358\n",
      "z: -0.7729710340499878\n",
      "visibility: 0.9992160201072693\n",
      ", x: 0.2982773184776306\n",
      "y: 0.6013385057449341\n",
      "z: -0.7730043530464172\n",
      "visibility: 0.9992707967758179\n",
      ", x: 0.31258076429367065\n",
      "y: 0.5987661480903625\n",
      "z: -0.7729533910751343\n",
      "visibility: 0.9993041157722473\n",
      ", x: 0.2530192732810974\n",
      "y: 0.6154110431671143\n",
      "z: -0.7647801637649536\n",
      "visibility: 0.9990391135215759\n",
      ", x: 0.2434852421283722\n",
      "y: 0.6192070245742798\n",
      "z: -0.7638855576515198\n",
      "visibility: 0.9988770484924316\n",
      ", x: 0.23309414088726044\n",
      "y: 0.6232632398605347\n",
      "z: -0.7644186019897461\n",
      "visibility: 0.9986971616744995\n",
      ", x: 0.33841827511787415\n",
      "y: 0.6400917172431946\n",
      "z: -0.4000627398490906\n",
      "visibility: 0.9994429349899292\n",
      ", x: 0.2213476002216339\n",
      "y: 0.6701219081878662\n",
      "z: -0.2976323962211609\n",
      "visibility: 0.9991209506988525\n",
      ", x: 0.3179425299167633\n",
      "y: 0.7298351526260376\n",
      "z: -0.7018709182739258\n",
      "visibility: 0.9991536736488342\n",
      ", x: 0.2733369469642639\n",
      "y: 0.7423801422119141\n",
      "z: -0.6850842833518982\n",
      "visibility: 0.998809814453125\n",
      ", x: 0.5803477168083191\n",
      "y: 0.9195778965950012\n",
      "z: -0.3283105194568634\n",
      "visibility: 0.9967721104621887\n",
      ", x: 0.13913750648498535\n",
      "y: 1.0405253171920776\n",
      "z: -0.06713756918907166\n",
      "visibility: 0.966293454170227\n",
      ", x: 0.957610011100769\n",
      "y: 0.7203155755996704\n",
      "z: -0.9918648600578308\n",
      "visibility: 0.9750288724899292\n",
      ", x: 0.043005093932151794\n",
      "y: 1.47193443775177\n",
      "z: 0.24685052037239075\n",
      "visibility: 0.15305189788341522\n",
      ", x: 0.8163148164749146\n",
      "y: 0.2062022089958191\n",
      "z: -1.5706865787506104\n",
      "visibility: 0.9851469993591309\n",
      ", x: -0.07756959646940231\n",
      "y: 1.7514053583145142\n",
      "z: 0.0612410232424736\n",
      "visibility: 0.0571109801530838\n",
      ", x: 0.7918849587440491\n",
      "y: 0.007636922411620617\n",
      "z: -1.706026315689087\n",
      "visibility: 0.943886935710907\n",
      ", x: -0.12437935918569565\n",
      "y: 1.864058256149292\n",
      "z: 0.05203748494386673\n",
      "visibility: 0.07488447427749634\n",
      ", x: 0.7477070093154907\n",
      "y: 0.028557229787111282\n",
      "z: -1.5999982357025146\n",
      "visibility: 0.9481958746910095\n",
      ", x: -0.10917564481496811\n",
      "y: 1.8561069965362549\n",
      "z: -0.07943107187747955\n",
      "visibility: 0.12090650945901871\n",
      ", x: 0.7429009079933167\n",
      "y: 0.10774395614862442\n",
      "z: -1.5562512874603271\n",
      "visibility: 0.9461944103240967\n",
      ", x: -0.08729991316795349\n",
      "y: 1.81741201877594\n",
      "z: -0.008650429546833038\n",
      "visibility: 0.14052855968475342\n",
      ", x: 0.6054795384407043\n",
      "y: 1.8566486835479736\n",
      "z: -0.1426791250705719\n",
      "visibility: 0.005743005778640509\n",
      ", x: 0.284745991230011\n",
      "y: 1.9029334783554077\n",
      "z: 0.14810319244861603\n",
      "visibility: 0.003064676420763135\n",
      ", x: 0.6608619093894958\n",
      "y: 2.5994386672973633\n",
      "z: -0.20168106257915497\n",
      "visibility: 0.0014398794155567884\n",
      ", x: 0.35007837414741516\n",
      "y: 2.6426892280578613\n",
      "z: 0.25166866183280945\n",
      "visibility: 0.00047373195411637425\n",
      ", x: 0.717474102973938\n",
      "y: 3.2479259967803955\n",
      "z: 0.3743012547492981\n",
      "visibility: 0.00011622409510891885\n",
      ", x: 0.4184536039829254\n",
      "y: 3.2896721363067627\n",
      "z: 0.6708401441574097\n",
      "visibility: 1.3576413948612753e-05\n",
      ", x: 0.7381883859634399\n",
      "y: 3.341277599334717\n",
      "z: 0.3993072211742401\n",
      "visibility: 0.00014983689470682293\n",
      ", x: 0.4211026728153229\n",
      "y: 3.381722927093506\n",
      "z: 0.6909068822860718\n",
      "visibility: 9.819855768000707e-05\n",
      ", x: 0.6850678324699402\n",
      "y: 3.45296049118042\n",
      "z: -0.3149239420890808\n",
      "visibility: 0.00020302376651670784\n",
      ", x: 0.48953643441200256\n",
      "y: 3.506178855895996\n",
      "z: -0.046213217079639435\n",
      "visibility: 0.00012163008796051145\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enum 'PoseLandmark'>\n"
     ]
    }
   ],
   "source": [
    "print (mp_pose.PoseLandmark) #enum data type #https://www.geeksforgeeks.org/enum-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mp_pose.PoseLandmark is a map of all the 33 landmarks, which you can use to get the landmark values from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseLandmark.NOSE\n",
      "PoseLandmark.LEFT_EYE_INNER\n",
      "PoseLandmark.LEFT_EYE\n",
      "PoseLandmark.LEFT_EYE_OUTER\n",
      "PoseLandmark.RIGHT_EYE_INNER\n",
      "PoseLandmark.RIGHT_EYE\n",
      "PoseLandmark.RIGHT_EYE_OUTER\n",
      "PoseLandmark.LEFT_EAR\n",
      "PoseLandmark.RIGHT_EAR\n",
      "PoseLandmark.MOUTH_LEFT\n",
      "PoseLandmark.MOUTH_RIGHT\n",
      "PoseLandmark.LEFT_SHOULDER\n",
      "PoseLandmark.RIGHT_SHOULDER\n",
      "PoseLandmark.LEFT_ELBOW\n",
      "PoseLandmark.RIGHT_ELBOW\n",
      "PoseLandmark.LEFT_WRIST\n",
      "PoseLandmark.RIGHT_WRIST\n",
      "PoseLandmark.LEFT_PINKY\n",
      "PoseLandmark.RIGHT_PINKY\n",
      "PoseLandmark.LEFT_INDEX\n",
      "PoseLandmark.RIGHT_INDEX\n",
      "PoseLandmark.LEFT_THUMB\n",
      "PoseLandmark.RIGHT_THUMB\n",
      "PoseLandmark.LEFT_HIP\n",
      "PoseLandmark.RIGHT_HIP\n",
      "PoseLandmark.LEFT_KNEE\n",
      "PoseLandmark.RIGHT_KNEE\n",
      "PoseLandmark.LEFT_ANKLE\n",
      "PoseLandmark.RIGHT_ANKLE\n",
      "PoseLandmark.LEFT_HEEL\n",
      "PoseLandmark.RIGHT_HEEL\n",
      "PoseLandmark.LEFT_FOOT_INDEX\n",
      "PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "for l in mp_pose.PoseLandmark:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.6850678324699402\n",
       "y: 3.45296049118042\n",
       "z: -0.3149239420890808\n",
       "visibility: 0.00020302376651670784"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CALCULATE ANGLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angles(a,b,c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians =np.arctan2(c[1]-b[1],c[0]-b[0])-np.arctan2(a[1]-b[1],a[0]-b[0])\n",
    "    angle = np.abs(radians*180/np.pi)\n",
    "\n",
    "    if angle > 180 :\n",
    "        angle = 360 - angle\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5803477168083191, 0.9195778965950012],\n",
       " [0.957610011100769, 0.7203155755996704],\n",
       " [0.8163148164749146, 0.2062022089958191])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoulder,elbow,wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens the video feed and close with the press 'q'\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "\n",
    "        results=pose.process(image)\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # extract the landmarks\n",
    "        try :\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        \n",
    "        shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "        elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "        wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "        angle = calculate_angles(shoulder,elbow,wrist)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale = 0.5\n",
    "        color = (255, 0, 0)\n",
    "        thickness = 2\n",
    "        \n",
    "        cv2.putText(image, str(angle),tuple(np.multiply(elbow,[640,480]).astype(int)), font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "    \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7909938097000122, 1.2658627033233643]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elbow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CURL COUNTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# opens the video feed and close with the press 'q'\n",
    "counter =0\n",
    "stage = None\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "\n",
    "        results=pose.process(image)\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # extract the landmarks\n",
    "        try :\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]           \n",
    "            angle = calculate_angles(shoulder,elbow,wrist)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 0.5\n",
    "            color = (255, 0, 0) \n",
    "            thickness = 2\n",
    "        \n",
    "            cv2.putText(image, str(angle),tuple(np.multiply(elbow,[640,480]).astype(int)), font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "            # rep counter condition \n",
    "            if angle > 160 :\n",
    "                stage = 'down'\n",
    "            if angle < 30 and stage =='down':\n",
    "                stage = 'up'\n",
    "                counter = counter +1\n",
    "                print(counter)\n",
    "\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # print the rep count on screen\n",
    "        cv2.rectangle(image,(0,0),(225,73),(255, 192, 203),-1)\n",
    "        cv2.putText(image,'REPS',(15,12),font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        cv2.putText(image,str(counter),(10,60),font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        # print the stage on screen\n",
    "       \n",
    "        cv2.putText(image,'STAGE',(60,12),font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        cv2.putText(image,stage,(60,60),font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "    \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e89c96e578d160d0ca2222b986fdee87f9f30c42e5ce70cfc2538cbc67af61d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
